# Dashboard Delivery Guide

This playbook explains how to assemble the Payments Analytics dashboards in Tableau or Looker using the curated marts generated by `python etl/run_pipeline.py`. Follow these instructions end-to-end to keep Sales, Marketing, Finance, and Operations stakeholders aligned.

## Data Connections

### Tableau Desktop (CSV extracts)
1. Run `python etl/run_pipeline.py --rows 2000000` to refresh `data/marts/*.csv`.
2. In Tableau Desktop, choose **Connect → Text/CSV** and browse to the desired mart (for example `data/marts/kpi_daily.csv`).
3. Set the file locale to *English (United States)*, confirm field types (dates, numbers), and add the table to the canvas.
4. Repeat for each mart needed in the workbook and create relationships on shared keys (`day`, `month`, `industry`, `merchant_id`).
5. Save as a packaged workbook (`.twbx`) so the extracts travel with the file.

### Tableau Desktop (DuckDB live connection)
1. Install the [DuckDB ODBC driver](https://duckdb.org/docs/clients/odbc/optional_installation.html).
2. Add a new **Other Databases (ODBC)** connection and point to `data/analytics.duckdb`.
3. Authenticate anonymously, then drag the views `v_kpi_daily`, `v_kpi_monthly`, etc., directly into the model. This option keeps data live for ad‑hoc drilling without re-exporting CSVs.

### Looker (uploaded extracts)
1. From the Looker UI, create a persistent derived table (PDT) project or use the **Upload Data** beta feature.
2. Upload each mart CSV and name them `marts.kpi_daily`, `marts.kpi_monthly`, etc.
3. In LookML, define views with dimensions/measures that mirror the CSV columns. Example:
	 ```lookml
	 view: kpi_daily {
		 dimension_group: day { type: time; timeframes: [date, week, month]; sql: ${TABLE}.day ;; }
		 measure: gpv { type: sum; sql: ${TABLE}.gpv ;; }
		 measure: approval_rate { type: number; sql: ${TABLE}.approval_rate ;; }
	 }
	 ```
4. Build an Explore that joins the relevant views on shared keys and expose dashboards via Looker’s Dashboard (beta) experience.

### Looker (DuckDB via external DB)
If your Looker instance can connect to DuckDB (through MotherDuck or a warehouse mirror), create a connection that references `analytics.duckdb`. Then point LookML views directly at the DuckDB views. This keeps Looker and Tableau modeling aligned.

### Python (fallback visualization)
When BI licenses are unavailable, analysts can read the marts with pandas/matplotlib or seaborn notebooks located under `notebooks/`. Replicate the layout defined in `dashboards/dashboard_spec.md` to keep parity with Tableau/Looker deliverables.

## Workbook Structure

| Dashboard | Stakeholder | Description |
| --- | --- | --- |
| Executive Overview | C-suite, Finance leads | Single-page KPI tiles, sparkline trends, and narrative callouts covering GPV, approvals, and fee yield. |
| Sales & Merchant Performance Drilldown | Sales directors, Account Management | Rank merchants, slice by industry/region, and inspect MoM deltas. |
| Approval & Decline Operations | Risk, Payments Ops | Surfaces channel-level decline reasons, issuer mix, and 7-day rolling rates. |
| Retention & Cohort Health | Marketing, Lifecycle | Visualizes merchant/customer cohorts, retention curves, and drop-off alerts. |

Each dashboard gets its own Tableau worksheet/Looker dashboard page; combine them in a workbook named **Payments Executive Suite**.

## Global Filters

Apply these filters to every worksheet/dashboard and set them to **Apply to all using related data sources** (Tableau) or **All tiles** (Looker):
- Date range (supports both day and month granularity).
- Region.
- Industry.
- Merchant size (small/medium/enterprise).
- Channel (pos, ecom, inapp).
- Payment method (card, ach, wallet).

## Mart-to-Component Mapping

| Dashboard Component | Data Source |
| --- | --- |
| Executive KPI tiles & daily trend lines | `data/marts/kpi_daily.csv` and `data/marts/kpi_monthly.csv` |
| Monthly MoM growth waterfall | `kpi_monthly.csv` |
| Industry × region heatmap | `industry_heatmap.csv` |
| Merchant leaderboard, drillable table | `top_merchants.csv` |
| Decline reason by channel stacked bars | `decline_drivers.csv` |
| Retention cohort matrix & curves | `merchant_cohorts.csv` |
| Narrative annotations (e.g., YoY callouts) | Derived from the same marts; no extra source |

## Publishing & Screenshot Workflow
1. Refresh marts (`python etl/run_pipeline.py`).
2. Refresh Tableau extracts or Looker PDTs.
3. Validate filters and interactivity per `dashboards/dashboard_spec.md` acceptance criteria.
4. Capture screenshots as described in `dashboards/screenshots/SHOTLIST.md` and store files beside the shotlist.
5. Archive the packaged workbook / LookML commit alongside the run summary for auditability.
